{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "890cbc3f-b778-4350-9e54-8d54c7317ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'install the packages to run this code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"install the packages to run this code\"\"\"\n",
    "#%pip install matplotlib tifffile scipy tqdm pybaselines opencv-python #plotly #need to do this through conda install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85c69df9-e7e7-426f-99e8-77954cb5a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "import cv2\n",
    "#from PIL import Image\n",
    "#from pybaselines.whittaker import asls\n",
    "from scipy import interpolate\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.signal import cheby1, filtfilt, find_peaks, peak_widths\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62cc9f86-5430-4173-a401-febf13719ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frames(video):\n",
    "    \"\"\"\n",
    "    Loads in tif stacks as a 3d array. Make sure the dtype is 12.\n",
    "    :param video: path to the file, including file name.tif\n",
    "\n",
    "    :return: 3d array of 128x128 x timeseries\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"loading video, please wait...\")\n",
    "    frames = tifffile.imread(video)\n",
    "    print(\"dimensions are\", frames.shape, \"as a\", frames.dtype)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "269cd9b7-ded6-40e5-a592-ce63e3cd6cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_plot(array1d, title_label = \"output\", xaxis_label = \"duration\", yaxis_label = \"intensity\"):\n",
    "    \"\"\"make plotly interactive plots\"\"\"\n",
    "    fig = px.line(array1d)\n",
    "    fig.update_layout(\n",
    "    title= title_label,\n",
    "    xaxis=dict(title=xaxis_label),\n",
    "    yaxis=dict(title=yaxis_label),\n",
    "    xaxis_rangeslider_visible=True,\n",
    "    showlegend=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3f1592c-b30e-4330-9a34-61ef2b21f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frame(frames:np.ndarray, frame_number, cmap = 'jet', color_label = \"N/A\"):\n",
    "    \"\"\"\n",
    "    plots a frame of interest, to check if the video was loaded in properly\n",
    "    :param frames: 3d array loaded in with tifffile\n",
    "    :param frame_number: frame of interest to plot\n",
    "    :param cmap: colormap used, set to jet as default\n",
    "    \"\"\"\n",
    "\n",
    "    image = frames[frame_number, :, :]\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(image, cmap=cmap)\n",
    "    plt.colorbar(im, label = color_label)\n",
    "    ax.grid(True)\n",
    "    ax.axis('on')\n",
    "    print(\"frame number\", frame_number, \"plotted\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acfcb98c-ddca-48ed-a207-ddebd69946ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_mean(frames):\n",
    "    \"\"\"\n",
    "    calculate and plot the signal over time\n",
    "    \n",
    "    :param frames: 3d array loaded in with tifffile\n",
    "    :return: 1d array where each frame intensity is averaged\n",
    "    \"\"\"\n",
    "    \n",
    "    mean_timecourse = frames.mean(axis=(1,2))\n",
    "\n",
    "    min_value = np.min(mean_timecourse)     # Find the minimum value in the signal array\n",
    "    dark_frame_threshold = min_value + 0.2 * min_value     # Calculate the threshold as the minimum value plus 10%\n",
    "    indices = np.arange(len(frames))\n",
    "    \n",
    "    #plotting\n",
    "    print(\"default 20% threshold is\", dark_frame_threshold, \"Determine if adjustments need to be made\")\n",
    "    interactive_plot(mean_timecourse, title_label = \"raw mean timecourse\", xaxis_label = \"frame number (30 fps)\", yaxis_label = \"intensity value (A.U)\")\n",
    "\n",
    "    return mean_timecourse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0125976d-e496-4ec3-ab48-09d310cf8180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dark_frames(frames, signal, threshold = 0.2):\n",
    "    \"\"\"\n",
    "    calculate where the dark frames are at the start and end of the trial\n",
    "\n",
    "    :param frames: 3d array loaded in with tifffile\n",
    "    :param signal: 1d array mean_time course array\n",
    "    :param threshold: a percent above the minimum value, default set to 20%\n",
    "\n",
    "    return: \n",
    "    \"\"\"\n",
    "    \n",
    "    min_value = np.min(signal)     # Find the minimum value in the signal array\n",
    "    dark_frame_threshold = min_value + threshold * min_value     # Calculate the threshold as the minimum value plus 10%\n",
    "    \n",
    "    brain_indices = np.where(signal > dark_frame_threshold)[0]\n",
    "    start_index = brain_indices[0]+1\n",
    "    end_index = brain_indices[-1]\n",
    "    \n",
    "    frames = frames[start_index:end_index, :, :]\n",
    "    signal = signal[start_index:end_index]\n",
    "\n",
    "    #plotting\n",
    "    print(\"threshold determined to be:\", dark_frame_threshold)\n",
    "    interactive_plot(signal, title_label = \"mean timecourse with dark frames removed\", xaxis_label = \"frame number (30 fps)\", yaxis_label = \"intensity value (A.U)\")\n",
    "    \n",
    "    return signal, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "193bf6a1-2fa1-4e14-9fae-30ed91c2a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_artifacts(timecourse, frames_between_double_flash = 20):\n",
    "    \"\"\"\n",
    "    extract indices where the artifact flash exists, as a function of 3 times the standard deviation of the global mean\n",
    "    :param timecourse: 1d array of the mean time course\n",
    "    :param frames_between_double_flash: the set time between two flashes in the double flash condition, default set to 20, always estimate higher\n",
    "\n",
    "    :return: array of where the signal is above the mean, artifact flashes\n",
    "    \"\"\"\n",
    "\n",
    "    T_mean = timecourse.mean()\n",
    "    std = timecourse.std()\n",
    "    artifact_indices = find_peaks(timecourse, height=(T_mean + 3 * std), distance=10)[0] #indescriminatly finds all the flashes\n",
    "\n",
    "    \"\"\" THIS PART IS FOR USE WHEN NEEDING TO SEPARATE SINGLE AND DOUBLE\"\"\"\n",
    "    time_diff = np.diff(artifact_indices) #determine the time between each peak, if it is 15 frames it is double, 320 frames is single\n",
    "\n",
    "    single_flash = []\n",
    "    double_flash = []\n",
    "\n",
    "    for i in range(len(artifact_indices)):\n",
    "        is_double_peak = (i > 0 and artifact_indices[i] - artifact_indices[i - 1] < frames_between_double_flash) or \\\n",
    "                         (i < len(artifact_indices) - 1 and artifact_indices[i + 1] - artifact_indices[i] < frames_between_double_flash)\n",
    "        if is_double_peak:\n",
    "            double_flash.append([artifact_indices[i], artifact_indices[i-1]])\n",
    "        else:\n",
    "            single_flash.append(artifact_indices[i])\n",
    "        \n",
    "    print(\"Number of double_flash:\", len(double_flash))\n",
    "    print(\"Number of single_flash:\", len(single_flash))\n",
    "    print(\"Number of total flashes:\", len(artifact_indices))\n",
    "\n",
    "    \"\"\"SECTION END\"\"\"\n",
    "    \n",
    "    return artifact_indices #,single_flash, double_flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5ce40c5-ebac-46dc-b3cb-1b1ab0ba9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(no_dark_frames, artifact_indices):\n",
    "    \"\"\"\n",
    "    interpolate over the artifacts, representing a total of 5 frames. \n",
    "\n",
    "    :param frames: 3d array with dark frames removed, DO NOT USE ORIGINAL \"FRAMES\" (includes each pixel value over time)\n",
    "    :param artifact_indices: index of where the artifact are located in the frames array\n",
    "    \n",
    "\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"interpolating artifact frames...\")\n",
    "    interp_indices = []        #make the indices that need to be interpolated, organized in groups of 5\n",
    "    for index in artifact_indices:\n",
    "        start = index-3        #add 3 frame padding before, to ensure the entire artifact is removed\n",
    "        end = index+3          #add 3 frame padding after, to ensure the entire artifact is removed\n",
    "        group = []\n",
    "        for new_index in range(start, end+1):        #loop within to ensure each array within the array is a total of 7 (for each flash of light)\n",
    "            group.append(new_index)\n",
    "        interp_indices.append(group)\n",
    "\n",
    "    x = [0, 6]                                                                  #between the two interpolated side, split into equaL segments\n",
    "    xnew = np.linspace(0, 6, np.shape(interp_indices)[1])                       #linear interpolate between the two x values, at equal increments\n",
    "    for g in tqdm(range(len(interp_indices[:]))):                                                 #tqdm is loading package (GUI), loops 3 dimensions of array\n",
    "        y_2d = [no_dark_frames[interp_indices[g][0]], no_dark_frames[interp_indices[g][-1]]]      #the frames which are usable on either side of artifact\n",
    "        for r in range(no_dark_frames.shape[1]):                                                  #iterate over each row of pixels\n",
    "            for c in range(no_dark_frames.shape[2]):                                              #iterate over each column of pixels\n",
    "                y = [y_2d[0][r, c], y_2d[1][r, c]]                              #represents each pixel [r,c], and the first and last frame to interpolate between\n",
    "                f = interp1d(x, y)                                              #interpolate the y values between these two-time segments\n",
    "                ynew = f(xnew)\n",
    "                no_dark_frames[interp_indices[g], r, c] = ynew[:]\n",
    "\n",
    "    #plot the interpolation\n",
    "    interactive_plot(no_dark_frames.mean(axis=(1,2)), title_label = \"mean timecourse with without artifacts\", xaxis_label = \"frame number (30 fps)\", yaxis_label = \"intensity value (A.U)\")\n",
    "    \n",
    "    return no_dark_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95147408-a485-41d5-a146-eee5654b5c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dff(data, duration = 10, frame_rate = 30, eps=1e-3):\n",
    "    \"\"\"\n",
    "     Calculate dF/F (moving centered mean) for tif video data.\n",
    "\n",
    "    :param data: 3d array with shape (depth, height, width), use the no artifact array\n",
    "    :param duration: Duration over which to average in seconds, default set at 10\n",
    "    :param frame_rate: Frame rate of the data in frames per second, default set at 30fps\n",
    "\n",
    "    :return: 3d array including the padding on both ends\n",
    "    \"\"\"\n",
    "    num_frames = int(duration * frame_rate)\n",
    "    \n",
    "    pad_size = int(num_frames / 2)\n",
    "    depth, height, width = data.shape[0], data.shape[1], data.shape[2]          # initialize the result array\n",
    "    dFF = np.ones((depth + 2 * pad_size, height, width), dtype=np.float32)\n",
    "    centered_mean_array = np.zeros_like(data)\n",
    "\n",
    "    data = np.concatenate((np.ones((pad_size, height, width)), data), axis=0)  # add padding to the data array (required for mean calculation)\n",
    "    data = np.concatenate((data, (np.ones((pad_size, height, width)))), axis=0)\n",
    "    for h in tqdm(range(height)):\n",
    "        for w in range(width):\n",
    "            data[0:pad_size,h,w] = data[pad_size:pad_size*2,h,w].mean()      #for each pixel (h=height, w=width), replace the start padding with the mean of the first 10 seconds\n",
    "            data[-pad_size:,h,w] = data[-pad_size*2:-pad_size,h,w].mean()\n",
    "\n",
    "    # iterate over frames starting from num_frames\n",
    "    for t in tqdm(range(pad_size, depth+pad_size)):        # t starts at pad_size (the adjusted index 0 after padding)\n",
    "        current_frame = data[t, :, :]        # get the current frame\n",
    "        centered_mean = np.mean(data[(t - pad_size):(t + pad_size), :, :], axis=0)       # calculate the centered mean with respect to the current frame (t)\n",
    "        centered_mean_array[t-pad_size,:,:] = centered_mean       #need subtract pad_size because the centered_mean_array does not include the padding      \n",
    "        dF = current_frame - centered_mean               # calculate dF\n",
    "        dFF[t, :, :] = (dF / (centered_mean + eps))              # calculate dF/F and store in the result array\n",
    "\n",
    "    return dFF[pad_size:-pad_size, :, :], centered_mean_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b3e9f79-f724-440d-afaf-cec9121ee410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing(data):\n",
    "    \"\"\"\n",
    "    Smooth the data using a Gaussian filter for the spatial dimension and\n",
    "    Chebyshev filter for the temporal dimension.\n",
    "\n",
    "    :param data: The dff 3d array with shape (depth, height, width), dff signal\n",
    "    \n",
    "    :return: Normalized 3d array with shape (depth, height, width) with spatial and temporal smoothing\n",
    "    \"\"\"\n",
    "    \n",
    "    #spatial smoothing\n",
    "    data =  gaussian_filter(data, sigma=2.0, radius=3)\n",
    "\n",
    "    #temporal smoothing with t\n",
    "    fs = 30.0  # sampling frequency\n",
    "    Ny = 0.5 * fs  # Nyquist frequency\n",
    "\n",
    "    lp = 0.1  # lower bound of the desired frequency band\n",
    "    hp = Ny - 0.001  # upper bound of the desired frequency band\n",
    "\n",
    "    # design the Chebyshev type I filter (see SciPy documentation for details)\n",
    "    chebyshev = cheby1(N=2,    #2nd Order\n",
    "                       rp=0.5,    #max ripple allowed below unity gain in the passband\n",
    "                       Wn=[lp / Ny, hp / Ny], #Wn is in half-cycles / sample\n",
    "                       btype='band',\n",
    "                       analog=False,\n",
    "                       output='ba')     #backwards compatibility\n",
    "\n",
    "     # initialize the result array\n",
    "    result = np.empty_like(data)\n",
    "    depth, height, width = data.shape[0], data.shape[1], data.shape[2]\n",
    "\n",
    "\n",
    "    # apply the filter along the time axis to each pixel (temporal dimension)\n",
    "    for h in tqdm(range(height)):\n",
    "        for w in range(width):\n",
    "            result[:, h, w] = filtfilt(b=chebyshev[0], a=chebyshev[1], x=data[:, h, w])\n",
    "\n",
    "    # normalize the result\n",
    "    result = (result - result.min()) / (result.max() - result.min())\n",
    "    np.clip(result, 0, 1)  # clip values to be between 0 and 1\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef40cbff-1c31-4d57-8f1d-8501c90c4d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_video(array3d, frame_rate, codec_type = 'XVID', output_filename = 'cortical_processed_video.avi'):\n",
    "    # Assuming your 3D array is named 'intensity_data' with shape (num_frames, 128, 128)\n",
    "    # Replace this with your actual data\n",
    "    num_frames = len(smoothed_signal)\n",
    "    height, width = smoothed_signal[1].shape\n",
    "\n",
    "    # Define video parameters\n",
    "    output_file = output_filename\n",
    "    fps = frame_rate  # Frames per second\n",
    "    codec = codec_type  # Video codec (use XVID for AVI format)\n",
    "\n",
    "    # Create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "    out = cv2.VideoWriter(output_file, fourcc, fps, (width, height))\n",
    "\n",
    "    min_intensity = np.min(smoothed_signal)\n",
    "    max_intensity = np.max(smoothed_signal)\n",
    "\n",
    "    # Normalize float32 data to 8-bit for visualization\n",
    "    normalized_data = ((smoothed_signal - min_intensity) / (max_intensity - min_intensity) * 255.0).astype(np.uint8)\n",
    "\n",
    "    # Write each frame to the video file\n",
    "    for slice in smoothed_signal:\n",
    "        # Convert the 2D array to a color image (assuming grayscale intensity data)\n",
    "        slice_rgb = cv2.cvtColor(slice, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # Write the frame to the video file\n",
    "        out.write(slice_rgb)\n",
    "\n",
    "    # Release the VideoWriter object\n",
    "    out.release()\n",
    "\n",
    "    print(\"Video generated successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
